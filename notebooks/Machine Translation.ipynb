{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import dill as pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import dali.core as D\n",
    "from dali.data import Lines, DiscoverFiles, BatchBenefactor\n",
    "from dali.data.batch import TranslationBatch\n",
    "from dali.data.translation import TranslationFiles, TranslationMapper, build_vocabs, iterate_examples\n",
    "\n",
    "from dali.utils import (\n",
    "    Vocab,\n",
    "    median_smoothing,\n",
    "    subsample,\n",
    "    throttled,\n",
    "    pickle_globals,\n",
    "    unpickle_globals,\n",
    ")\n",
    "from dali import beam_search\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.config.default_device = 'gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "DATASET_PATH = \"/home/sidor/datasets/translation/pl_en/europarl/\"\n",
    "FROM_LANG = \"pl\"\n",
    "TO_LANG   = \"en\"\n",
    "FROM_VOCAB_SIZE = 20000\n",
    "TO_VOCAB_SIZE   = 20000\n",
    "\n",
    "# batching\n",
    "MINIBATCH = 128\n",
    "SENTENCE_LENGTH_BOUNDS = (None, 27)\n",
    "SENTENCES_UNTIL_MINIBATCH = 1000*MINIBATCH\n",
    "\n",
    "# network sizes\n",
    "INPUT_SIZE = 512\n",
    "HIDDENS = [512, 512, 512, 512]\n",
    "SOFTMAX_INPUT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impatient User Detected, file processing halted, proceeding to build vocab.\n",
      "plvocabulary containts 20002 words\n",
      "envocabulary containts 20002 words\n"
     ]
    }
   ],
   "source": [
    "# you can press stop at any time if you think enough samples were collected.\n",
    "vocabs = build_vocabs(DATASET_PATH, FROM_LANG, TO_LANG, from_max_size=FROM_VOCAB_SIZE, to_max_size=TO_VOCAB_SIZE)\n",
    "print (FROM_LANG + \"vocabulary containts\", len(vocabs[0]), \"words\")\n",
    "print (TO_LANG   + \"vocabulary containts\", len(vocabs[1]), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dataset_iterator():\n",
    "    return iterate_examples(DATASET_PATH, FROM_LANG, TO_LANG, vocabs, \n",
    "                            minibatch_size=MINIBATCH,\n",
    "                            sentence_length_bounds=SENTENCE_LENGTH_BOUNDS,\n",
    "                            sentences_until_minibatch=SENTENCES_UNTIL_MINIBATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TranslationModel(object):\n",
    "    def __init__(self, input_size, hiddens, \n",
    "                       encoder_vocab_size, decoder_vocab_size,\n",
    "                       softmax_input_size=None, dtype=np.float32):\n",
    "        self.input_size = input_size\n",
    "        self.hiddens    = hiddens\n",
    "        self.encoder_vocab_size = encoder_vocab_size\n",
    "        self.decoder_vocab_size = decoder_vocab_size\n",
    "        self.softmax_input_size = softmax_input_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.encoder_embedding = D.random.uniform(-0.05, 0.05, (encoder_vocab_size, input_size), dtype=dtype)\n",
    "        self.decoder_embedding = D.random.uniform(-0.05, 0.05, (decoder_vocab_size, input_size), dtype=dtype)\n",
    "        \n",
    "        self.encoder_lstm    = D.StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        self.decoder_lstm    = D.StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        \n",
    "        if self.softmax_input_size is not None:\n",
    "            self.predecoder = D.Layer(self.hiddens[-1], self.softmax_input_size)\n",
    "            self.decoder = D.Layer(self.softmax_input_size, decoder_vocab_size, dtype=dtype)\n",
    "        else:    \n",
    "            self.decoder = D.Layer(hiddens[-1], decoder_vocab_size, dtype=dtype)\n",
    "    \n",
    "    def decode_state(self, state):\n",
    "        if self.softmax_input_size is not None:\n",
    "            decoder_input = self.predecoder.activate(state[-1].hidden)\n",
    "        else:\n",
    "            decoder_input = state[-1].hidden\n",
    "        return self.decoder.activate(decoder_input)\n",
    "        \n",
    "    def error(self, batch):\n",
    "        error = D.Mat(1,1)\n",
    "        state = self.encoder_lstm.initial_states()\n",
    "        for ts in range(batch.timesteps):\n",
    "            inputs  = batch.inputs(ts)\n",
    "            targets = batch.targets(ts)\n",
    "            if ts < batch.from_timesteps:\n",
    "                assert targets is None\n",
    "                encoded = self.encoder_embedding[inputs]\n",
    "                state = self.encoder_lstm.activate(encoded, state)\n",
    "            else:\n",
    "                assert inputs is None\n",
    "                decoded = self.decode_state(state)\n",
    "                # mask the error - only for the relevant sentences\n",
    "                tstep_error = batch.masks(ts).T() * D.MatOps.softmax_cross_entropy(decoded, targets)\n",
    "                error = error + tstep_error.sum()\n",
    "                # feedback the predictions\n",
    "                if ts + 1 != batch.timesteps:\n",
    "                    # for the last timestep encoding is not necessary\n",
    "                    encoded = self.decoder_embedding[targets]\n",
    "                    state = self.decoder_lstm.activate(encoded, state)\n",
    "\n",
    "        return error / batch.to_tokens\n",
    "    \n",
    "    def sample(self, input_sentence, temperature=1.0, **kwargs):\n",
    "        with D.NoBackprop():\n",
    "            state = self.encoder_lstm.initial_states()\n",
    "            for word_idx in input_sentence:\n",
    "                encoded = self.encoder_embedding[word_idx]\n",
    "                state = self.encoder_lstm.activate(encoded, state)\n",
    "            def candidate_scores(state):\n",
    "                decoded = self.decode_state(state)\n",
    "                return D.MatOps.softmax(decoded, temperature=temperature).log()\n",
    "            def make_choice(state, candidate_idx):\n",
    "                encoded = self.decoder_embedding[candidate_idx]\n",
    "                return self.decoder_lstm.activate(encoded, state)\n",
    "\n",
    "            return beam_search(state,\n",
    "                               candidate_scores,\n",
    "                               make_choice,\n",
    "                               **kwargs)\n",
    "    \n",
    "    def parameters(self):\n",
    "        ret = ([self.encoder_embedding,\n",
    "               self.decoder_embedding]      \n",
    "            + self.encoder_lstm.parameters() \n",
    "            + self.decoder_lstm.parameters() \n",
    "            + self.decoder.parameters())\n",
    "        if self.softmax_input_size is not None:\n",
    "            ret.extend(self.predecoder.parameters())\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_reconstructions(model, example_pair, temperature=1.0):\n",
    "    from_words, to_words = example_pair\n",
    "    from_vocab, to_vocab = vocabs\n",
    "    from_with_unk = ' '.join(reversed(from_vocab.decode(from_vocab.encode(from_words))))\n",
    "    to_with_unk   = ' '.join(to_vocab.decode(to_vocab.encode(to_words)))\n",
    "    print('TRANSLATING: %s' % from_with_unk)\n",
    "    print('REFERENCE:   %s' % to_with_unk)\n",
    "    print('')\n",
    "    for solution, score, _ in model.sample(from_vocab.encode(from_words, True), \n",
    "                                           eos_symbol=to_vocab.eos,\n",
    "                                           max_sequence_length=SENTENCE_LENGTH_BOUNDS[1] + 1,\n",
    "                                           blacklist=[], #to_vocab.unk],\n",
    "                                           temperature=temperature):\n",
    "        score = math.exp(score.w[0])\n",
    "        # reveal the unks\n",
    "        solution = ' '.join(to_vocab.decode(solution, False))\n",
    "        print('    %f => %s' % (score, to_vocab.decode(solution, True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model  = TranslationModel(INPUT_SIZE, HIDDENS, len(vocabs[0]), len(vocabs[1]), softmax_input_size=SOFTMAX_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.w = np.random.uniform(-0.08, 0.08, size=param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "solver = D.SGD(params)\n",
    "solver.step_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data            = []\n",
    "error_evolution = []\n",
    "epoch_error     = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) continue running previous attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle_globals(\"/home/sidor/tmp/translation_experiment\")\n",
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:              6.13255233013\n",
      "Time per batch:     0.6750621419874346\n",
      "Words per second:   6211.625630946709\n",
      "Batches processed:  1123\n",
      "TRANSLATING: Chciałabym wezwać do **UNK** podejścia do **UNK** .\n",
      "REFERENCE:   I would like to call for a realistic approach to **UNK** .\n",
      "\n",
      "    0.000000 => In of of of of of of of of of of of of of of of of of of of of of of of of of of of\n",
      "    0.000000 => In of that of of of of of of of of of of of of of of of of of of of of of of of of of\n",
      "    0.000000 => In of of of of of of of of of of of of of of of of of of of of of of of of of of that\n",
      "    0.000000 => In of of of of of of of of of of of of of of of of of of of of of of of of of that of\n",
      "    0.000000 => In of of of of of of of that of of of of of of of of of of of of of of of of of of of\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7c549e899bfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mbatch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-f039765a807a>\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m                 \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_lstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_error = 0.0\n",
    "total_time  = 0.0\n",
    "num_words, num_targets, num_batches = 0, 0, 0\n",
    "\n",
    "@throttled(5)\n",
    "def report(example):\n",
    "    if num_batches == 0 or num_words == 0 or abs(total_time) < 1e-6:\n",
    "        return\n",
    "    clear_output()\n",
    "    print('Error:             ', total_error / num_batches)\n",
    "    print('Time per batch:    ', total_time  / num_batches)\n",
    "    print('Words per second:  ', num_words   / total_time )\n",
    "    print('Batches processed: ', num_batches)\n",
    "    show_reconstructions(model, example)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "batch_end_time, batch_start_time = None, None\n",
    "\n",
    "while True:\n",
    "    for batch in data:    \n",
    "        example_pair = random.choice(batch.sentence_pairs)\n",
    "        report(example_pair) \n",
    "            \n",
    "        batch_start_time = time.time()\n",
    "        error = model.error(batch)\n",
    "\n",
    "        error.grad()\n",
    "        D.Graph.backward()\n",
    "        solver.step(params)\n",
    "        batch_end_time = time.time()\n",
    "\n",
    "        epoch_error.append(error.w[0,0])\n",
    "        \n",
    "        total_error   += error.w[0, 0]\n",
    "        total_time += batch_end_time - batch_start_time\n",
    "\n",
    "        num_words   += batch.from_tokens + batch.to_tokens\n",
    "        num_targets += batch.from_tokens + batch.to_tokens\n",
    "        num_batches    += 1\n",
    "\n",
    "        # free memory as soon as possible\n",
    "        del batch\n",
    "    \n",
    "    if len(epoch_error) > 10000:\n",
    "        epoch_error = median_smoothing(epoch_error, window=len(epoch_error) // 100)\n",
    "        epoch_error = subsample(epoch_error, maximum_length=1000)\n",
    "        epoch_error = []\n",
    "\n",
    "        error_evolution.append(epoch_error)\n",
    "    \n",
    "    data = create_dataset_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_globals(\"/home/sidor/tmp/translation_experiment\", [\"model\", \"vocabs\", \"solver\", \"data\", \"error_evolution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f893f687710>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f893f8429b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flatten_error():\n",
    "    y = []\n",
    "    for error_epoch in error_evolution:\n",
    "        y.extend(error_epoch)\n",
    "    x = [float(t) / 1000.0 for t in range(len(y))]\n",
    "    return x,y\n",
    "    \n",
    "plt.plot(*flatten_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f893f4b7438>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f893f6e3208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r= median_smoothing(epoch_error, window=500)\n",
    "\n",
    "plt.plot(range(len(r)), r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
