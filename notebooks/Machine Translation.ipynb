{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import dill as pickle\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import dali.core as D\n",
    "from dali.data import Lines, DiscoverFiles, BatchBenefactor\n",
    "from dali.data.batch import TranslationBatch\n",
    "from dali.data.translation import TranslationFiles, TranslationMapper, build_vocabs, iterate_examples\n",
    "\n",
    "from dali.utils import (\n",
    "    Vocab,\n",
    "    median_smoothing,\n",
    "    subsample,\n",
    "    throttled,\n",
    "    pickle_globals,\n",
    "    unpickle_globals,\n",
    ")\n",
    "from dali import beam_search\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.config.default_device = 'gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "DATASET_PATH = \"/home/sidor/datasets/translation/\"\n",
    "FROM_LANG = \"pl\"\n",
    "TO_LANG   = \"en\"\n",
    "FROM_VOCAB_SIZE = 20000\n",
    "TO_VOCAB_SIZE   = 20000\n",
    "\n",
    "# batching\n",
    "MINIBATCH = 128\n",
    "SENTENCE_LENGTH_BOUNDS = (None, 25)\n",
    "\n",
    "# network sizes\n",
    "INPUT_SIZE = 512\n",
    "HIDDENS = [512, 512, 512, 512]\n",
    "SOFTMAX_INPUT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impatient User Detected, file processing halted, proceeding to build vocab.\n",
      "plvocabulary containts 20002 words\n",
      "envocabulary containts 20002 words\n"
     ]
    }
   ],
   "source": [
    "# you can press stop at any time if you think enough samples were collected.\n",
    "vocabs = build_vocabs(DATASET_PATH, FROM_LANG, TO_LANG, from_max_size=FROM_VOCAB_SIZE, to_max_size=TO_VOCAB_SIZE)\n",
    "print (FROM_LANG + \"vocabulary containts\", len(vocabs[0]), \"words\")\n",
    "print (TO_LANG   + \"vocabulary containts\", len(vocabs[1]), \"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dataset_iterator():\n",
    "    return iterate_examples(DATASET_PATH, FROM_LANG, TO_LANG, vocabs, \n",
    "                            minibatch_size=MINIBATCH,\n",
    "                            sentence_length_bounds=SENTENCE_LENGTH_BOUNDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TranslationModel(object):\n",
    "    def __init__(self, input_size, hiddens, \n",
    "                       encoder_vocab_size, decoder_vocab_size,\n",
    "                       softmax_input_size=None, dtype=np.float32):\n",
    "        self.input_size = input_size\n",
    "        self.hiddens    = hiddens\n",
    "        self.encoder_vocab_size = encoder_vocab_size\n",
    "        self.decoder_vocab_size = decoder_vocab_size\n",
    "        self.softmax_input_size = softmax_input_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.encoder_embedding = D.random.uniform(-0.05, 0.05, (encoder_vocab_size, input_size), dtype=dtype)\n",
    "        self.decoder_embedding = D.random.uniform(-0.05, 0.05, (decoder_vocab_size, input_size), dtype=dtype)\n",
    "        \n",
    "        self.encoder_lstm    = D.StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        self.decoder_lstm    = D.StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        \n",
    "        if self.softmax_input_size is not None:\n",
    "            self.predecoder = D.Layer(self.hiddens[-1], self.softmax_input_size)\n",
    "            self.decoder = D.Layer(self.softmax_input_size, decoder_vocab_size, dtype=dtype)\n",
    "        else:    \n",
    "            self.decoder = D.Layer(hiddens[-1], decoder_vocab_size, dtype=dtype)\n",
    "    \n",
    "    def decode_state(self, state):\n",
    "        if self.softmax_input_size is not None:\n",
    "            decoder_input = self.predecoder.activate(state[-1].hidden)\n",
    "        else:\n",
    "            decoder_input = state[-1].hidden\n",
    "        return self.decoder.activate(decoder_input)\n",
    "        \n",
    "    def error(self, batch):\n",
    "        error = D.Mat(1,1)\n",
    "        state = self.encoder_lstm.initial_states()\n",
    "        for ts in range(batch.timesteps):\n",
    "            inputs  = batch.inputs(ts)\n",
    "            targets = batch.targets(ts)\n",
    "            if ts < batch.from_timesteps:\n",
    "                assert targets is None\n",
    "                encoded = self.encoder_embedding[inputs]\n",
    "                state = self.encoder_lstm.activate(encoded, state)\n",
    "            else:\n",
    "                assert inputs is None\n",
    "                decoded = self.decode_state(state)\n",
    "                # mask the error - only for the relevant sentences\n",
    "                tstep_error = batch.masks(ts).T() * D.MatOps.softmax_cross_entropy(decoded, targets)\n",
    "                error = error + tstep_error.sum()\n",
    "                # feedback the predictions\n",
    "                if ts +1 != batch.timesteps:\n",
    "                    # for the last timestep encoding is not necessary\n",
    "                    encoded = self.decoder_embedding[targets]\n",
    "                    state = self.decoder_lstm.activate(encoded, state)\n",
    "\n",
    "        return error\n",
    "    \n",
    "    def sample(self, input_sentence, temperature=1.0, **kwargs):\n",
    "        with D.NoBackprop():\n",
    "            state = self.encoder_lstm.initial_states()\n",
    "            for word_idx in input_sentence:\n",
    "                encoded = self.encoder_embedding[word_idx]\n",
    "                state = self.encoder_lstm.activate(encoded, state)\n",
    "            def candidate_scores(state):\n",
    "                decoded = self.decode_state(state)\n",
    "                return D.MatOps.softmax(decoded, temperature=temperature).log()\n",
    "            def make_choice(state, candidate_idx):\n",
    "                encoded = self.decoder_embedding[candidate_idx]\n",
    "                return self.decoder_lstm.activate(encoded, state)\n",
    "\n",
    "            return beam_search(state,\n",
    "                               candidate_scores,\n",
    "                               make_choice,\n",
    "                               **kwargs)\n",
    "    \n",
    "    def parameters(self):\n",
    "        ret = ([self.encoder_embedding,\n",
    "               self.decoder_embedding]      \n",
    "            + self.encoder_lstm.parameters() \n",
    "            + self.decoder_lstm.parameters() \n",
    "            + self.decoder.parameters())\n",
    "        if self.softmax_input_size is not None:\n",
    "            ret.extend(self.predecoder.parameters())\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_reconstructions(model, words, temperature=1.0):\n",
    "    from_vocab, to_vocab = vocabs\n",
    "    priming = ' '.join(from_vocab.decode(from_vocab.encode(words)))\n",
    "    print('TRANSLATING: %s' % priming)\n",
    "\n",
    "    for solution, score, _ in model.sample(from_vocab.encode(words, True), \n",
    "                                           eos_symbol=to_vocab.eos,\n",
    "                                           max_sequence_length=SENTENCE_LENGTH_BOUNDS[1],\n",
    "                                           blacklist=[], #to_vocab.unk],\n",
    "                                           temperature=temperature):\n",
    "        score = math.exp(score.w[0])\n",
    "        # reveal the unks\n",
    "        solution = ' '.join(to_vocab.decode(solution, False))\n",
    "        print('    %f => %s' % (score, to_vocab.decode(solution, True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model  = TranslationModel(INPUT_SIZE, HIDDENS, len(vocabs[0]), len(vocabs[1]), softmax_input_size=SOFTMAX_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "solver = D.SGD(params)\n",
    "solver.step_size = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data            = []\n",
    "error_evolution = []\n",
    "epoch_error     = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) continue running previous attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle_globals(\"/home/sidor/tmp/translation_experiment\")\n",
    "params = model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:              7.67680861964\n",
      "Time per batch:     0.7815548583080895\n",
      "Words per second:   2826.9288796731566\n",
      "Batches processed:  190\n",
      "TRANSLATING: Mam dla ciebie ważne zadanie .\n",
      "    0.720099 => That people the fine fine fine fine fine his his his fine fine fine fine fine fine fine fine fine his his his his his his his\n",
      "    0.223076 => That people the fine fine fine fine fine fine his his fine fine fine fine fine fine fine fine fine his his his his his his his\n",
      "    0.043245 => That people the fine fine fine fine fine his his fine fine fine fine fine fine fine fine fine fine his his his his his his his\n",
      "    0.013397 => That people the fine fine fine fine fine fine his fine fine fine fine fine fine fine fine fine fine his his his his his his his\n",
      "    0.000087 => That people the fine fine fine fine his his his his fine fine fine fine fine fine fine fine fine his his his his his his his\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c3b131d5fbec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mbatch_end_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_error = 0.0\n",
    "total_time  = 0.0\n",
    "num_words, num_targets, num_batches = 0, 0, 0\n",
    "\n",
    "@throttled(5)\n",
    "def report(example):\n",
    "    if num_batches == 0 or num_words == 0 or abs(total_time) < 1e-6:\n",
    "        return\n",
    "    clear_output()\n",
    "    print('Error:             ', total_error / num_targets)\n",
    "    print('Time per batch:    ', total_time  / num_batches)\n",
    "    print('Words per second:  ', num_words   / total_time )\n",
    "    print('Batches processed: ', num_batches)\n",
    "    show_reconstructions(model, example)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "batch_end_time, batch_start_time = None, None\n",
    "\n",
    "while True:\n",
    "    for batch in data:    \n",
    "        from_sentence = random.choice(batch.sentence_pairs)[0]\n",
    "        report(from_sentence) \n",
    "            \n",
    "        batch_start_time = time.time()\n",
    "        error = model.error(batch)\n",
    "\n",
    "        error.grad()\n",
    "        D.Graph.backward()\n",
    "        solver.step(params)\n",
    "        batch_end_time = time.time()\n",
    "\n",
    "        epoch_error.append(error.w[0,0] / batch.to_tokens)\n",
    "        \n",
    "        total_error   += error.w[0, 0]\n",
    "        total_time += batch_end_time - batch_start_time\n",
    "\n",
    "        num_words   += batch.from_tokens + batch.to_tokens\n",
    "        num_targets += batch.from_tokens + batch.to_tokens\n",
    "        num_batches    += 1\n",
    "\n",
    "        # free memory as soon as possible\n",
    "        del batch\n",
    "    \n",
    "    if len(epoch_error) > 0:\n",
    "        epoch_error = median_smoothing(epoch_error, window=len(epoch_error) / 100)\n",
    "        epoch_error = subsample(epoch_error, maximum_length=1000)\n",
    "        epoch_error = []\n",
    "\n",
    "        error_evolution.append(epoch_error)\n",
    "    \n",
    "    data = create_dataset_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_globals(\"/home/sidor/tmp/translation_experiment\", [\"model\", \"solver\", \"data\", \"error_evolution\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bbaff4a20>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEACAYAAAC6d6FnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3bdc1e72b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def flatten_error():\n",
    "    y = []\n",
    "    for error_epoch in error_evolution:\n",
    "        y.extend(error_epoch)\n",
    "    x = [float(t) / 1000.0 for t in range(len(y))]\n",
    "    return x,y\n",
    "    \n",
    "plt.plot(*flatten_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gdzie', 'ja', 'jestem', '?']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
