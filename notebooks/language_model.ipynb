{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import dali.core as D\n",
    "from dali.data import LineExtractor, discover_files, batched_reducer, process_files\n",
    "from dali.data.batch import LMBatch\n",
    "\n",
    "from dali.utils import Vocab, median_smoothing, throttled\n",
    "from dali import beam_search\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D.config.default_device = 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first 10k words from glove\n",
    "GLOVE_VOCAB = '/home/sidor/projects/Dali/data/glove/vocab10k.txt'\n",
    "# Bookcorpus - pretokenized\n",
    "BOOKCORPUS  = '/home/sidor/datasets/bookcorpus/'\n",
    "\n",
    "# network sizes\n",
    "INPUT_SIZE = 250\n",
    "HIDDENS = [250, 250]\n",
    "\n",
    "# dataset / training parameters\n",
    "MINIBATCH = 256\n",
    "SENTENCES_UNTIL_MINIBATCH = 1000 * MINIBATCH\n",
    "SENTENCE_LENGTH=(2, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove_vocab = Vocab()\n",
    "glove_vocab.add(LineExtractor()(GLOVE_VOCAB))\n",
    "glove_vocab.add(LMBatch.START_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_bookcorpus(path, vocab, minibatch_size, sentences_until_minibatch=None, sentence_length_bounds=(2, 20)):\n",
    "    sentences_until_minibatch = sentences_until_minibatch or 10000 * minibatch_size\n",
    "    files   = discover_files(BOOKCORPUS, \".txt\")\n",
    "    mapper  = LineExtractor() \\\n",
    "              .lower()        \\\n",
    "              .split_spaces() \\\n",
    "              .bound_length(*sentence_length_bounds)\n",
    "    reducer = batched_reducer(minibatch_size,\n",
    "                              LMBatch.given_vocab(glove_vocab, store_originals=True),\n",
    "                              sentences_until_minibatch)\n",
    "    return process_files(files=files, mapper=mapper, reducer=reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "example_generator = extract_bookcorpus(BOOKCORPUS, glove_vocab, MINIBATCH, \n",
    "                                    SENTENCES_UNTIL_MINIBATCH, sentence_length_bounds=SENTENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "    def __init__(self, input_size, hiddens, vocab_size, dtype=np.float32):\n",
    "        self.input_size = input_size\n",
    "        self.hiddens    = hiddens\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.encoder = D.random.uniform(-0.05, 0.05, (vocab_size, input_size), dtype=dtype)\n",
    "        self.lstm    = D.StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        self.decoder = D.Layer(hiddens[-1], vocab_size, dtype=dtype)\n",
    "    \n",
    "    def error(self, batch):\n",
    "        error = D.Mat(1,1)\n",
    "        state = self.lstm.initial_states()\n",
    "        for ts in range(batch.timesteps):\n",
    "            inputs  = batch.inputs(ts)\n",
    "            targets = batch.targets(ts)\n",
    "            if inputs:\n",
    "                encoded = self.encoder[batch.inputs(ts)]\n",
    "            else:\n",
    "                encoded = Mat(1, self.input_size)\n",
    "            state = self.lstm.activate(encoded, state)\n",
    "            if targets:\n",
    "                decoded = self.decoder.activate(state[-1].hidden)\n",
    "                error = error + D.MatOps.softmax_cross_entropy(decoded, targets).sum()\n",
    "        return error\n",
    "    \n",
    "    def sample(self, priming, temperature=1.0, **kwargs):\n",
    "        with D.NoBackprop():\n",
    "            state = self.lstm.initial_states()\n",
    "            for word_idx in priming:\n",
    "                encoded = self.encoder[word_idx]\n",
    "                state = self.lstm.activate(encoded, state)\n",
    "            def candidate_scores(state):\n",
    "                return D.MatOps.softmax(self.decoder.activate(state[-1].hidden), temperature=temperature).log()\n",
    "            def make_choice(state, candidate_idx):\n",
    "                encoded = self.encoder[candidate_idx]\n",
    "                return self.lstm.activate(encoded, state)\n",
    "\n",
    "            return beam_search(state,\n",
    "                               candidate_scores,\n",
    "                               make_choice,\n",
    "                               **kwargs)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.encoder] + self.lstm.parameters() + self.decoder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_reconstructions(model, words, temperature=1.0):\n",
    "    for solution, score, _ in model.sample(glove_vocab.encode([LMBatch.START_TOKEN] + words), \n",
    "                                           eos_symbol=glove_vocab.eos,\n",
    "                                           max_sequence_length=20,\n",
    "                                           blacklist=[glove_vocab.unk],\n",
    "                                           temperature=temperature):\n",
    "        score = math.exp(score.w[0])\n",
    "        priming = ' '.join(words)\n",
    "        solution = ' '.join(glove_vocab.decode(solution, False))\n",
    "        print('%f => [%s] %s' % (score, priming, solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model  = LanguageModel(INPUT_SIZE, HIDDENS, len(glove_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "s = D.AdaGrad(params)\n",
    "s.step_size = 0.003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_evolution = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:              5.39217371803\n",
      "Time per batch:     0.8139708504747989\n",
      "Words per second:   2469.5225901671392\n",
      "Batches processed:  134\n",
      "0.075618 => [‘same travel] **EOS**\n",
      "0.006036 => [‘same travel] . **EOS**\n",
      "0.003867 => [‘same travel] , **EOS**\n",
      "0.000664 => [‘same travel] . . **EOS**\n",
      "0.000098 => [‘same travel] . . . **EOS**\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-db882a1c2fbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexample_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mbatch_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a4223fcb084a>\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mdecoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatOps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_error, num_words = 0.0, 0\n",
    "batch_time, num_batches = 0.0, 0\n",
    "\n",
    "@throttled(5)\n",
    "def report(example):\n",
    "    if num_batches == 0 or num_words == 0 or abs(batch_time) < 1e-6:\n",
    "        return\n",
    "    clear_output()\n",
    "    print('Error:             ', total_error / num_words)\n",
    "    print('Time per batch:    ', batch_time  / num_batches)\n",
    "    print('Words per second:  ', num_words   / batch_time )\n",
    "    print('Batches processed: ', num_batches)\n",
    "    show_reconstructions(model, example)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "\n",
    "batch_end_time, batch_start_time = None, None\n",
    "\n",
    "for batch in example_generator:    \n",
    "    batch_start_time = time.time()\n",
    "    error = model.error(batch)\n",
    "\n",
    "    error.grad()\n",
    "    D.Graph.backward()\n",
    "    s.step(params)\n",
    "    batch_end_time = time.time()\n",
    "\n",
    "    error_evolution.append(error.w[0,0] / sum(batch.sentence_lengths))\n",
    "    \n",
    "    total_error += error.w[0, 0]\n",
    "    num_words   += sum(batch.sentence_lengths)\n",
    "        \n",
    "    if batch_end_time is not None and batch_start_time is not None:\n",
    "        batch_time += batch_end_time - batch_start_time\n",
    "    num_batches    += 1\n",
    "    \n",
    "    example = batch.sentences[0]\n",
    "    example_len = random.randint(1, len(example))\n",
    "    \n",
    "    report(example[:example_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1ed92fb5f8>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFRFJREFUeJzt3XuQnXV9x/H3YXMnJBiQJFx0aSAIBEmoF3RkXDEgWpXx\n0gplvNHiOKODKArB1pLRXkC8tR0db+UiCrUiY6W1iLZGVKy3QICQcBEwhFuQcEcqyLd//J5Ndpez\n2T2353l+Z9+vmWfO2d1znueb7J7Pec7393ueByRJkiRJkiRJkiRJkiRJklp2LnAvcN2I7y0Avgfc\nBFwB7FpBXZIkYKcJfn4ecMyY760ihfhS4L+LryVJNTXI6D3xjcDC4v6i4mtJUgUm2hNvZiGpxUJx\nu3AHj5Uk9VA7IT5SFIskqQLT2njOvaQ2yj3AYmDLOI+7BVjSZl2SNFX9GtivmyscZHRP/OPA6cX9\nVcBZ4zwv9z301VUX0KHVVRfQodVVF9CB1VUX0KHVVRfQodVVF9ChlrJzonbKxcBVwAHAHcA7SaF9\nFGmK4ZGMH+KSpB6bqJ1y/DjfX9ntQiRJret0YLOfram6gA6tqbqADq2puoAOrKm6gA6tqbqADq2p\nuoB+kXtPXJKq0NWeuCSpxgxxScqYIS5JGTPEJSljhrgkZcwQl6SMGeKSlDFDXJIyZohLUsYMcUnK\nmCEuSRkzxCUpY4a4JGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypghLkkZM8QlKWOGuCRlzBCXpIwZ\n4pKUMUNckjJmiEtSxgxxScpYJyH+PuA64PriviQpE8tIAT4LGAC+BywZ85gouyhJ6gMtZWe7e+LP\nA34GPAH8Afgh8MY21yVJalO7IX49cASwAJgD/Amwd7eKkiRNzrQ2n7cROBu4AngMuBp4ultFSZIm\np90QBzi3WAD+HtjU5DGrR9xfUyySpO2GiqV0exS3zwE2APPG/DwgZpdbkiRlr7RJIVcC64FrgFc0\nLyReVFYxktQnajOzLyDeXXURkpSZUqYYTtZhPV6/JE1pvQ7xP+7x+iVJPRIQj0PMqLoQScpIrdop\ntwIH93gbkjRl9TrE12JfXJJ6xhCXpIwZ4pKkpgJiF4hHITo5vF+SppI6DWw2HgHuBA7o7XYkaWoq\n4/Jsa3G+uCT1RFkhbl9cknrAEJckNVU052MBxMMQZbxhSFLu6jSwCdDYCtwP7Nf7bUnS1FLW3rEt\nFUnqgbJC/FcY4pLUdWXuiTvNUJIyMqI5HwshHoBoVFeOJGWhTpdnG/XlZoh9qylFkrJRt9kp2zi4\nKUldZohLUsYMcUlSU2N74ntBbHFwU5J2qLY98btIxe1Z4jYlqa+VGOKNwPniktRVZZ+Uyr64JHWR\nIS5JaqpJcz72TQf9SJLGUdcjNiHNTIkH0mH4kqQmSpudcgawHrgOuAiYOfFTtg1uruhgu5KkQrsh\nPgicROpvHwIMAMdN8rmellaSuqTdEH8YeBKYA0wrbu+c5HOdZihJNfAu4BFgC3Bhk5+P09eJpRC3\n9a4sScpaSz3xaW1uZAlwCqmt8hDwDeAE4GtjHrd6xP01xXILsFu6gHJja5vbl6R+MVQspXoL8OUR\nX78V+OyYx+zg3SSuhHhl98uSpOyVMjtlI3A4MBtoACuBG1p4vgf9SFIXtBvi64CvAL8Eri2+98UW\nnm+IS1LN7aidcjDEjeWVIknZqPMRm9t+NA3iUYh55ZUjSVmo7fnER2g8RTrSc3k125ek/lBRiAP2\nxSWpY4a4JKmpCfo6sQLi+nJKkaRs5DCwCRAzIB6HmFNOOZKUhRwGNgEavwc2AM+vrgZJyluVPXHw\ntLSS1JGqQ9zT0kpSB+oQ4u6JS1INTaI5H7OLwc1JXNpNkqaEXAY2ARq/I51ffFm1dUhSnqpup4At\nFUlqmyEuSRkzxCVJTU2yOR9zIR6DmN7bciQpCzkNbAI0HgU2AQdWXYkk5aYGIQ7YUpGkthjikpQx\nQ1yS1FQLzfnYFeIRiIHelSNJWchtYBOg8SCwBdi/6kokKSc1CXHA09JKUsvqFOKellaSWlS3EHdP\nXJJqosWLfcazIR6EqNMbiySVLZcLJTd9yiaIJd0vRZKykePslG1sqUhSC9oN8QOAq0csDwEnd6Ee\nQ1ySSrYTcDewz5jvt9NOeS3Ed7tQkyTlqvSe+NHAj7tTSCyG+C1Eo9OiJClTpffEjwMu6sJ6gMbd\nwJM8c69ektTEtA6fPwN4HXD6OD9fPeL+mmKZyHBffFMHdUlSLoaKpRLHApeP87M2+zrxMYiPtluQ\nJGWu1HbK8cDFHa5jLGeoSFIJdgZ+C+wyzs/b3RN/LsRdbdYkSbnL+YhNSDNT4v40U0WSppysj9gE\nGkE6Le2KqiuRpLqrYYgDnpZWkialziHu4KYkVaiD5nzsB/Gb7pUiSdnIfWAT0jnF4yGI3btXjiRl\nIfeBTYDG06SzIzq4KUk7UNMQB+yLS9KEDHFJUlMdNufjQIhbulOKJGWjHwY2AWIA4lGIXbtTjiRl\noR8GNgEafwDWAcurrkSS6qrGIQ7YF5ekHTLEJUlNdaE5H4dC3ND5eiQpG/0ysAkQ0yEeh9i583VJ\nUhb6ZWAToPEksB44tOpKJKmOah7iQDq3uKellaQmcghxBzclaRyGuCSpqS6NsMasYnBzVnfWJ0m1\n1k8DmwCNJ4CbgEOqrkSS6iaDEAdsqUhSU4a4JGUslxB3mqEklayLh47GzsXg5ozurVOSaqnfBjYB\nGo8BtwEHVV2JJNVJJiEO2BeXpGcwxCUpY52E+K7AJcAG4Abg8K5UND5DXJK66ALgxOL+NGD+mJ93\n+Zy4Mb+45uZAd9crSbVSyvnE5wO3ll9I3Azh4KakflbK7JR9gfuA80htji8Bc9pcVyucLy5JI0zr\n4HmHAe8FfgF8BlgF/M2Yx60ecX9NsXRiuC9+YYfrkaS6GCqWUi0izdse9jLgP8Y8phftlJUQP+z+\neiWpNkppp9wD3AEsLb5eSbqMWq9dDayAyGlqpCTV0qGkVso64FJ6Pjtl22pvh9i/N+uWpMr109Xu\nm672Uoi39GbdklS5fjx3yige9CNJhRxD3GmGklSCXrVTFkJshWj0Zv2SVKl+74kDxJ0Qg71bvyRV\npu974mBfXJJ6rpd74u+F2FTczu7ddiSpdFOhnQIQL4b4FsQ9EKsg5vV2e5JUiqkS4ts2swziqxC/\nhfgYxO7lbFeSemKqhfi2zS2B+EIxc+VTEHuVu31J6oqpGuLbNrsXxCeLMP8ixH7V1CFJbZnqIb5t\n87tDfLRos3wN4pBq65GkSTHER4t5EKdB3A3x72lAVJJqqybZWaNCkpgN8R6I30B8H+JIj/qUVEO1\nyc7aFDJaTId4O8RGiJ9CvM4wl1QjtcnO2hTSXAxAvBliLcS1EMen70lSpWqTnbUpZMeiAXEMxI8g\nbob4S4iZVVclacqqTXbWppDJiyMg/gviDogTbLNIqkBtsrM2hbQuXgRxPcTXIRZUXY2kKaU22Vmb\nQtoTsyE+U+yVr6y6GklTRm2yszaFdCaOKoL80xCzqq5GUt+rTXbWppDOxQKIfytaLIdWXY2kvlab\n7KxNId0RDYi3QtwH8UGIXC+oIaneapOdtSmku2IQ4kqIH0A8p+pqRotnQXwY4jaID1RdjaS21CY7\na1NI98UAxOkQWyD+vOpqIPYZcebG84tTCtwI8ddVVyapZbXJztoU0juxAuIGiIvTXnDp2z+4CO2t\nRYjvM+Jni4oe/t86313KSm2yszaF9FbMhvhH0jU/jyxpmy+DuIx0aboPj/8GErtDXF0EvEEu5aE2\n2VmbQsoRR0NsJl1VqAdTEWMniGMhfgJxC8S7mdRFouNZED+H+KyDsf0gji7elF/iG/NYMRfinyB+\nAfHNYlrw+yHeBPFCiIWZ/J+1lJ29/AdFj9dfQ7Eb8HngecAJ0Li2C+ucmdbFh4DHgLOBS6HxhxbW\nMQ/4DnAj8K7Wnqt6iEOAc4AlwDeANwNPAf8CXAiNLRUWVwPxcuBc4EfAF4E9gec0WeYBdwCbxlnu\ngMbjZVc/RmnZeTtwLXA18PNxCpmCogHxtmIq4qnt7/3GvGIq42aI79Lx+c9jLsT/kK5yNK399ahc\nsRjiS8Ug+skQM4rvN0jn+jkP4gGISyFeO/V+t7Fz0c7cnP79Ez5+DsRSiJUQJ0KshjiXdI2BmyB+\nV7x210J8q9iz/yDEn0EcDrFnCZ9oS8vO24AdnVdkiob4sNgX4sdFcO4z8eO3PW8xxD+QLit3EcTy\nLtY0m3SCr0u2h4HqKXaGOBPifohzIHbdwWPnkc6++VOIu4q/n6Xl1VqVOKJoLV5I185xFA2IPSBe\nAPFGiFOKFuklRVvynhTqPVVqiO9Wh0LqKwYgzij2oo6f4LFLSRd23grxz+lNoCc1zSz2MC7D0wjU\nUAwUe4h3kmY9tfh3EAdBfALiXtLxDO9Ibwj9JOYUwXoXxLEVbL/XrY7SsvNWUivll8BJVRZSf3EY\nxIZiz3rMTJJ4EWkQZkvx0e7ZJdQznXSGxivSC0L1EEdBrCs+wXV4LdiYDvGG4s36gaIlc3gJAdRj\n8dKi7XERaQyqH5WWnYuL22cD1wBHVFVIHmJOsYddTEWMV0OsIV3z8+Ty95ZiGsRXihp2KXfbGi2W\nQXynaA28qftBG3tCrCrCbz1prGaP7m6j12J20Va6O7U5+lol2XkmcGqTQlaPWIbKLKi+4lXFx8B1\npAtPTK+wlp2KFs5VEPOrq2OqikXF//+Wovfa43GKbYOh50M8SDaDofFi0jVxv17OJ9XSDTE6K0sJ\n8TnA8N7bzsBPgKPHPMY98XHFTvX5WBsN0gj8L/v442nNxByIj5AGLT/xzBZbKTXMgzgJ4n/ZPhi6\nf/l17EjMgjiLNJj4p1VXU6JSsnNfUgvlGuB64IyqClE3RAPibNIFozP7mJ2TGCgGGjcXe5V/VHVF\nSRxMOoBoC2kw9CSIvSuu6YVF6+eSKfg3WZvsrE0hmoxoFAOrG1IPVd0VrySdAuEqiJdUXU1zMSP1\nm+NfSVNc15NmgRzNpI4O7koNMyH+jjS75rj6fGItVW2yszaFqBWxCuJmanea3VzFQRD/CfFriDfn\nE0oxQJo59RHSbJlHIC4nHcZ+UG/+HXEYxHWkKbCLur/+bNQmO2tTiFoVp5DOSb6k6kryFQshPl+0\nKN6f9jBzFrsWe+lfgLiddMnCL6dedac9/ZgB8dFi7/uEfN7oeqY22VmbQtSOeHfxQj2g6kryETNJ\npyf+SNGO+BRdO5KwTqKR/i7iZNLUyIdJR4ueSZqLPtDCupaTZmpdBrF44sdPCbXJztoUonbFO0hH\nDi4rYVs7pdkR8ZYiDN4FMZRe2HXcM4vdiz73qaT59teSzrtxfbGHOoU+xcQs0rlIzin+H+4nXZP2\nL8YfII3pxe95C+lcQzX8HVfGsxiqm+I44DPAa6CxtkvrnAYcCKwADiuW5cBW0lHAG4BFwAHFMh24\niXQWxhtH3L+p92eciwHSmQOXA4eOuN0FWEeaoTV8ux4aT/S2nhzEnqQpx68CjgLuBb4LXE46y+D+\nwPnA3aSzat5ZTZ211VJ2GuKahHgD6RS7r4fGz1p87ixgGSmoh0N7GbAZWFssV6elcf8469gNWMr2\nUB++vwS4j2eG+43AJmg83WKtc4FDGB3WhxTbGBnW64DboeGnzQnFAOl3/qpiWQ48AZwGnO//YVOG\nuHohXkPae3oTNH40zmPmkoJveO96BSlwbyYF9XBor4PGI12oaQB4LqODfXhZANzC6GAfXh4C9mJ7\nUA+H9t7ADYwO62uh8WDntSqJ+cAANLZWXUmNGeLqlVgJXAQcTwrl4T3r4dt9gPWM3sO+rpoWQ8wl\nfWwfGezDQb8T6QIbwwesDYf2jdB4qvxapVEMcfVSHAF8GxggBd9wWK8FNkLjyQqLm4RokK7u8rAf\n5VVTtclOXyB9K+bg9TqlXqlNdtamEEnKSEvZ6d6UJGXMEJekjBnikpQxQ1ySMmaIS1LGDHFJypgh\nLkkZM8QlKWOGuCRlzBCXpIwZ4pKUMUNckjJmiEtSxgxxScqYIS5JGTPEJSljhrgkZazTEB8gXV/x\nsi7UIklqUach/j7gBvrzUmxDVRfQoaGqC+jQUNUFdGCo6gI6NFR1AR0aqrqAMnUS4nsDrwG+TE2u\nzNxlQ1UX0KGhqgvo0FDVBXRgqOoCOjRUdQEdGqq6gDJ1EuKfBj4EPN2lWiRJLWo3xF8LbCH1w/tx\nL1ySstBuAP898FbgKWAWMA/4JvC2EY+5BVjSUXWSNPX8GtivzA2+HGenSFIlujVPvB9np0iSJEn5\nOQbYCNwMnF5xLa3aB/gBsB64Hji52nLakvNBWLsClwAbSMcgHF5tOS07g/S3cx1wETCz2nImdC5w\nL6neYQuA7wE3AVeQfid11az+c0h/P+uAS4H5FdQ1Gc1qH3YqaebfglIrKgyQBjUHgenANcCBVRTS\npkXA8uL+XOBG8qof4APA14BvV11IGy4ATizuT6O+L8BmBoFb2R7cXwfeXlk1k3MEsILRQfJx4LTi\n/unAWWUX1YJm9R/F9lbxWdS3/ma1Q9qRvBy4jYpC/CVFAcNWFUuuvgW8suoiWrA38H3gFeS3Jz6f\nFIK5WkB6038W6Q3oMmBlpRVNziCjg2QjsLC4v6j4us4Gab43C/AG4KvlldKyQZ5Z+zeA5zPJEO/F\nCbD2Au4Y8fXm4ns5GiS9U/6s4jpakfNBWPsC9wHnAWuBLwFzKq2oNVuBTwKbgLuAB0lvqLlZSPqY\nT3G7cAePrbsTge9UXUQLjiVl5rWTfUIvQrxfZqrMJfVm3wc8WnEtk5X7QVjTgMOAzxW3j5HXp7gl\nwCmkN/89SX9DJ1RZUBcE+b6m/wr4PWlsIgdzgA8DZ4743oSv416E+J2kns6wfUjvLDmZTjp46auk\ndkouXgq8nvQx7GLgSOArlVbUms3F8ovi60tIYZ6LFwBXAfeTDoS7lPQ7yc29pDYKwGLSjkFu3kE6\nt1NOb6JLSDsA60iv4b2BXwF7lF3INNIRR4PADPIb2GyQgu/TVRfSoVwPwroSWFrcXw2cXV0pLTuU\nNKNpNunv6ALgPZVWNDmDPHNgc3hW2SrqOzA4bJDR9R9DmiG0eyXVtGaQ8fv5lQ1sAryaNMBzC2nK\nVU5eRuonX0NqS1xN+qPIzcvJc3bKoaQ98bpPDxvPaWyfYngB6VNdnV1M6t//njSW9U5ScHyfPKYY\njq3/RNLU5t+w/fX7ucqq27Hh2v+P7f/3I91KhSEuSZIkSZIkSZIkSZIkSZIkSZIkqUX/D8hMQNZL\n8TY3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ee51bf470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(median_smoothing(error_evolution, window=len(error_evolution) // 20 )[::10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59101"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.387494 => [where did] **EOS**\n",
      "0.002209 => [where did] . **EOS**\n",
      "0.000005 => [where did] . . **EOS**\n",
      "0.000000 => [where did] . . . **EOS**\n",
      "0.000000 => [where did] , **EOS**\n"
     ]
    }
   ],
   "source": [
    "show_reconstructions(model, \"where did\".split(' '), temperature=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "openf = False\n",
    "\n",
    "import pickle\n",
    "\n",
    "if openf:\n",
    "    with open(\"/home/sidor/tmp/lm.dali\", \"rb\") as f:\n",
    "        loaded_model = pickle.load(f)\n",
    "else:\n",
    "    with open(\"/home/sidor/tmp/lm.dali\", \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "openf = False\n",
    "\n",
    "import pickle\n",
    "\n",
    "if openf:\n",
    "    with open(\"/home/sidor/tmp/lm-solver.dali\", \"rb\") as f:\n",
    "        loaded_s = pickle.load(f)\n",
    "else:\n",
    "    with open(\"/home/sidor/tmp/lm-solver.dali\", \"wb\") as f:\n",
    "        pickle.dump(s, f)\n",
    "#batches_processed = 59094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.__class__ = LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
