{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.display import clear_output\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from test_dali import LSTM, Mat, LSTMState, StackedLSTM, MatOps, Layer, Graph, AdaDelta, config, random as drandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "was: cpu\n",
      "is gpu\n"
     ]
    }
   ],
   "source": [
    "print(\"was:\", config.default_device)\n",
    "config.default_device = 'gpu'\n",
    "print(\"is\", config.default_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu_allocated': True,\n",
       " 'cpu_fresh': True,\n",
       " 'gpu_allocated': False,\n",
       " 'gpu_fresh': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Mat(4,4)\n",
    "x.w\n",
    "x.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = drandom.uniform(0.5, size=(3,3), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpu_allocated': True,\n",
       " 'cpu_fresh': True,\n",
       " 'gpu_allocated': False,\n",
       " 'gpu_fresh': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.memory_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Throttled(object):\n",
    "    decorated_to_throttled = {}\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.last_time = None\n",
    "        \n",
    "    def maybe_run(self, min_time_since_last_run_s, f):\n",
    "        now = time.time()\n",
    "        if self.last_time is None or (now - self.last_time) > min_time_since_last_run_s:\n",
    "            self.last_time = now\n",
    "            return f()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def throttled(min_time_between_run_s):\n",
    "    def decorator(f):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            if f not in Throttled.decorated_to_throttled:\n",
    "                Throttled.decorated_to_throttled[f] = Throttled()\n",
    "            t = Throttled.decorated_to_throttled[f]\n",
    "            def ok_this_is_getting_ridiculous():\n",
    "                return f(*args, **kwargs)\n",
    "            return t.maybe_run(min_time_between_run_s, ok_this_is_getting_ridiculous)\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import types\n",
    "\n",
    "def apply_recursively_on_type(x, f, target_type, list_callback=None):\n",
    "    if type(x) == target_type:\n",
    "        return f(x)\n",
    "    elif type(x) == list or isinstance(x, types.GeneratorType):\n",
    "        ret = [ apply_recursively_on_type(el, f, target_type, list_callback) for el in x]\n",
    "        if list_callback and all(type(el) == target_type for el in x):\n",
    "            ret = list_callback(ret)\n",
    "        return ret\n",
    "    elif type(x) == dict:\n",
    "        res = {}\n",
    "        for k,v in x.items():\n",
    "            res[k] = apply_recursively_on_type(v, f, target_type, list_callback)\n",
    "        return res\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class VocabEncoded(int):\n",
    "    pass\n",
    "\n",
    "class Vocab(object):\n",
    "    UNK = '**UNK**'\n",
    "    EOS = '**EOS**'\n",
    "    \n",
    "    def __init__(self, add_eos=True, add_unk=True):\n",
    "        self.index2word = []\n",
    "        self.word2index = {}\n",
    "        self.eos = None\n",
    "        self.unk = None\n",
    "        if add_eos:\n",
    "            self.add(Vocab.UNK)\n",
    "        if add_unk:\n",
    "            self.add(Vocab.EOS)\n",
    "            \n",
    "    def __contains__(self, key):\n",
    "        if type(key) == int:\n",
    "            return key in range(len(self.index2word))\n",
    "        elif type(key) == str:\n",
    "            return key in self.word2index\n",
    "        else:\n",
    "            raise ValueError(\"expected(index or string)\")\n",
    "\n",
    "    def add(self, obj):\n",
    "        def add_f(word):\n",
    "            idx = self.word2index.get(word)\n",
    "            if idx is None:\n",
    "                idx = len(self.index2word)\n",
    "                self.index2word.append(word)\n",
    "                self.word2index[word] = idx\n",
    "                if word is Vocab.UNK:\n",
    "                    self.unk = idx\n",
    "                if word is Vocab.EOS:\n",
    "                    self.eos = idx\n",
    "            return word\n",
    "        apply_recursively_on_type(obj, add_f, str)\n",
    "    \n",
    "    def words(self):\n",
    "        return self.word2index.keys()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index2word)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if type(index) == int:\n",
    "            return self.index2word[index]\n",
    "        elif type(index) == str:\n",
    "            if self.unk is not None:\n",
    "                return VocabEncoded(self.word2index.get(index) or self.unk)\n",
    "            else:\n",
    "                return VocabEncoded(self.word2index[index])\n",
    "        else:\n",
    "            raise ValueError(\"expected(index or string)\")\n",
    "        \n",
    "    def decode(self, obj, strip_eos=False):\n",
    "        def decode_f(word_idx):\n",
    "            return self.index2word[word_idx]\n",
    "        def decode_list_f(lst):\n",
    "            if strip_eos:\n",
    "                assert self.eos is not None\n",
    "                return [el for el in lst if el != Vocab.EOS]\n",
    "            else:\n",
    "                return lst\n",
    "        return apply_recursively_on_type(obj, decode_f, VocabEncoded, list_callback=decode_list_f)\n",
    "                \n",
    "    def encode(self, obj, add_eos=False):\n",
    "        def encode_f(word):\n",
    "            if self.unk is not None:\n",
    "                return VocabEncoded(self.word2index.get(word) or self.unk)\n",
    "            else:\n",
    "                return VocabEncoded(self.word2index[word])\n",
    "        def encode_list_f(lst):\n",
    "            lst = [encode_f(word) for word in lst]\n",
    "            if add_eos:\n",
    "                assert self.eos is not None\n",
    "                lst.append(VocabEncoded(self.eos))\n",
    "            return lst\n",
    "        return apply_recursively_on_type(obj, lambda x:x, str, list_callback=encode_list_f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vocab_test1():\n",
    "    vocab = Vocab()\n",
    "    vocab.add([[{\n",
    "        'interesting_words': ['awesome', 'cat', 'lol'],\n",
    "        'daniel' : 'daniel',\n",
    "        'wtf':[[[[[[[[[[[['there']]]]]]]]]]]]\n",
    "    }]])\n",
    "    assert(set(vocab.words()) == set(['awesome', 'there', 'daniel', '**UNK**', 'cat', '**EOS**', 'lol']))\n",
    "    original = {1:{1:{1:[[[[[ 'awesome', 'but','staph', 'daniel' ]]]]]}}}\n",
    "    original_with_unks = {1: {1: {1: [[[[['awesome', '**UNK**', '**UNK**', 'daniel']]]]]}}}\n",
    "    encoded  = vocab.encode(original)\n",
    "    decoded  = vocab.decode(encoded)\n",
    "    assert original_with_unks == decoded\n",
    "\n",
    "    encoded  = vocab.encode(original, add_eos=True)\n",
    "    decoded  = vocab.decode(encoded, strip_eos=True)\n",
    "    assert original_with_unks == decoded\n",
    "vocab_test1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def process_files(files, mapper, reducer):\n",
    "    if files == str:\n",
    "        files = [files]\n",
    "    for file in files:\n",
    "        for element in mapper(file):\n",
    "            for res in reducer(element):\n",
    "                yield res\n",
    "\n",
    "def discover_files(root_path, extension=None):\n",
    "    for path, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            if extension is None or file.endswith(extension):\n",
    "                yield os.path.join(path, file)\n",
    "\n",
    "class Mapper(object):\n",
    "    FILTER      = 1\n",
    "    TRANSFORMER = 2\n",
    "    def __init__(self, map_f):\n",
    "        self.map_f      = map_f\n",
    "        self._transformations = []\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        for element in self.map_f(*args, **kwargs):\n",
    "            ignore = False\n",
    "            for transform_f in self._transformations:\n",
    "                element = transform_f(element)\n",
    "                if element is None:\n",
    "                    ignore = True\n",
    "                    break\n",
    "            if ignore:\n",
    "                continue\n",
    "            yield element\n",
    "    \n",
    "    def add_filter(self, filter_f):\n",
    "        def wrapper(element):\n",
    "            if filter_f(element):\n",
    "                return element\n",
    "            return None\n",
    "        self.add_transform(wrapper)\n",
    "        return self\n",
    "    \n",
    "    def add_transform(self, transform_f):\n",
    "        self._transformations.append(transform_f)\n",
    "        return self\n",
    "            \n",
    "class LineExtractor(Mapper):\n",
    "    def __init__(self):\n",
    "        def extract_lines(file):\n",
    "            with open(file, \"rt\") as f:\n",
    "                for line in f:\n",
    "                    yield line[:-1]\n",
    "        super(LineExtractor, self).__init__(extract_lines)\n",
    "            \n",
    "    def lower(self):\n",
    "        return self.add_transform(lambda x: x.lower())\n",
    "        \n",
    "            \n",
    "    def bound_length(self, lower_bound=None, upper_bound=None):\n",
    "        if lower_bound:\n",
    "            self.add_filter(lambda x: lower_bound <= len(x))\n",
    "        if lower_bound:\n",
    "            self.add_filter(lambda x: len(x) <= upper_bound)\n",
    "        return self\n",
    "    \n",
    "    def split_spaces(self):\n",
    "        return self.add_transform(lambda x: x.split(' '))\n",
    "\n",
    "def batched_reducer(minibatch_size,\n",
    "                    minibatch_f=lambda x:x,\n",
    "                    examples_until_minibatches=None,\n",
    "                    sorting_key=lambda x: len(x)):\n",
    "    collected = []\n",
    "    examples_until_minibatches = examples_until_minibatches or minibatch_size\n",
    "    def wrapper(el):\n",
    "        collected.append(el)\n",
    "        if len(collected) >= examples_until_minibatches:\n",
    "            collected.sort(key=sorting_key)\n",
    "            for i in range(0, len(collected), minibatch_size):\n",
    "                if i + minibatch_size < len(collected):\n",
    "                    yield minibatch_f(collected[i:(i + minibatch_size)])\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Batch(object):\n",
    "    def __init__(self):\n",
    "        self.timesteps = 0\n",
    "        self.examples  = 0\n",
    "    def inputs(timestep):\n",
    "        return None\n",
    "    def targets(timestep):\n",
    "        return None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'Batch(timesteps=%d, examples=%d)' % (self.timesteps, self.examples)\n",
    "\n",
    "class LMBatch(object):\n",
    "    START_TOKEN = '**START**'\n",
    "    @staticmethod\n",
    "    def given_vocab(vocab, **kwargs):\n",
    "        def wrapper(sentences):\n",
    "            return LMBatch(sentences, vocab, **kwargs)\n",
    "        return wrapper\n",
    "    \n",
    "    def __init__(self, sentences, vocab, store_originals=False, add_eos=True):\n",
    "        if store_originals:\n",
    "            self.sentences = sentences\n",
    "        sentences = [vocab.encode(s, add_eos=add_eos) for s in sentences]\n",
    "\n",
    "        self.sentence_lengths = [len(s) for s in sentences]\n",
    "\n",
    "        self.timesteps = max(self.sentence_lengths)\n",
    "        self.examples  = len(sentences)\n",
    "        # we add one index to account for start of sequence token\n",
    "        self.data = np.empty((self.timesteps + 1, self.examples))\n",
    "        # data is badded by EOS\n",
    "        self.data.fill(vocab.eos)\n",
    "        self.data[0,:].fill(vocab[LMBatch.START_TOKEN])\n",
    "        for example_idx, example in enumerate(sentences):\n",
    "            self.data[1:(len(example) + 1), example_idx] = example\n",
    "        self.data = Mat(self.data, borrow=True, dtype=np.int32)\n",
    "        \n",
    "    def inputs(self, timestep):\n",
    "        return self.data[timestep]\n",
    "    \n",
    "    def targets(self, timestep):\n",
    "         # predictions are offset by 1 to inputs, so\n",
    "        return self.data[timestep + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GLOVE_VOCAB = '/home/sidor/projects/Dali/data/glove/vocab10k.txt'\n",
    "BOOKCORPUS  = '/home/sidor/datasets/bookcorpus/'\n",
    "\n",
    "INPUT_SIZE = 250\n",
    "HIDDENS = [250,250]\n",
    "MINIBATCH = 256\n",
    "SENTENCES_UNTIL_MINIBATCH = 100 * MINIBATCH\n",
    "\n",
    "glove_vocab = Vocab()\n",
    "glove_vocab.add(LineExtractor()(GLOVE_VOCAB))\n",
    "glove_vocab.add(LMBatch.START_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_bookcorpus(path, vocab, minibatch_size, sentences_until_minibatch=None, sentence_length_bounds=(2, 20)):\n",
    "    sentences_until_minibatch = sentences_until_minibatch or 10000 * minibatch_size\n",
    "    files   = discover_files(BOOKCORPUS, \".txt\")\n",
    "    mapper  = LineExtractor() \\\n",
    "              .lower()        \\\n",
    "              .split_spaces() \\\n",
    "              .bound_length(*sentence_length_bounds)\n",
    "    reducer = batched_reducer(minibatch_size,\n",
    "                              LMBatch.given_vocab(glove_vocab, store_originals=True),\n",
    "                              sentences_until_minibatch)\n",
    "    return process_files(files=files, mapper=mapper, reducer=reducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LanguageModel(object):\n",
    "    def __init__(self, input_size, hiddens, vocab_size, dtype=np.float32):\n",
    "        self.input_size = input_size\n",
    "        self.hiddens    = hiddens\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dtype = dtype\n",
    "        \n",
    "        self.encoder = drandom.uniform(-0.05, 0.05, (vocab_size, input_size), dtype=dtype)\n",
    "        self.lstm = StackedLSTM(input_size, hiddens, dtype=dtype)\n",
    "        self.decoder = Layer(hiddens[-1], vocab_size, dtype=dtype)\n",
    "    \n",
    "    def error(self, batch):\n",
    "        error = Mat(1,1)\n",
    "        state = self.lstm.initial_states()\n",
    "        for ts in range(batch.timesteps):\n",
    "            inputs  = batch.inputs(ts)\n",
    "            targets = batch.targets(ts)\n",
    "            if inputs:\n",
    "                encoded = self.encoder[batch.inputs(ts)]\n",
    "            else:\n",
    "                encoded = Mat(1, self.input_size)\n",
    "            state = self.lstm.activate(encoded, state)\n",
    "            if targets:\n",
    "                decoded = self.decoder.activate(state[-1].hidden)\n",
    "                error = error + MatOps.softmax_cross_entropy(decoded, targets).sum()\n",
    "        return error\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.encoder] + self.lstm.parameters() + self.decoder.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model  = LanguageModel(INPUT_SIZE, HIDDENS, len(glove_vocab))\n",
    "params = model.parameters()\n",
    "s = AdaDelta(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:              7.81977070754\n",
      "Time per batch:     0.7004362146059672\n",
      "Words per second:   1695.7289974907605\n",
      "Batches processed:  12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-01070ce7e8c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mGraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_error, num_words = 0.0, 0\n",
    "\n",
    "reports = Throttled()\n",
    "\n",
    "total_error,    num_words   = 0.0, 0\n",
    "batch_time, num_batches = 0.0, 0\n",
    "\n",
    "@throttled(5)\n",
    "def report():\n",
    "    clear_output()\n",
    "    print('Error:             ', total_error / num_words)\n",
    "    print('Time per batch:    ', batch_time  / num_batches)\n",
    "    print('Words per second:  ', num_words   / batch_time )\n",
    "    print('Batches processed: ', num_batches)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "for batch in extract_bookcorpus(BOOKCORPUS, glove_vocab, MINIBATCH, SENTENCES_UNTIL_MINIBATCH):\n",
    "    batch_start_time = time.time()\n",
    "    error = model.error(batch)\n",
    "    batch_end_time = time.time()\n",
    "    \n",
    "    error.grad()\n",
    "    Graph.backward()\n",
    "    \n",
    "    s.step(params)\n",
    "    total_error += error.w[0, 0]\n",
    "    num_words   += sum(batch.sentence_lengths)\n",
    "    \n",
    "    batch_time += batch_end_time - batch_start_time\n",
    "    num_batches    += 1\n",
    "    \n",
    "    report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec186009e6f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.fill(3, size=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7308366f6098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.empty((3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
